{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "import spacy\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../v2/train.json', 'r') as f:\n",
    "    train_set = json.load(f)\n",
    "    \n",
    "with open('../v2/val.json', 'r') as f:\n",
    "    val_set = json.load(f)\n",
    "    \n",
    "with open('../v2/test.json', 'r') as f:\n",
    "    test_set = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = defaultdict(dict)\n",
    "\n",
    "for _set in [train_set, val_set, test_set]:\n",
    "    for img_path in _set:\n",
    "        for game_id in _set[img_path]:\n",
    "            chain = _set[img_path][game_id]\n",
    "            dataset[img_path][game_id] = chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-grained image domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vehicles**: person_motorcycle, car_motorcycle, bus_truck, car_truck  \n",
    "\n",
    "**Accessories**: person_suitcase, person_umbrella  \n",
    "\n",
    "**Food**: bowl_dining_table, cup_dining_table, cake_dining_table  \n",
    "\n",
    "**Appliances**: person_oven, dining_table_refrigerator, person_refrigerator  \n",
    "\n",
    "**Laptops**: dining_table_laptop, couch_laptop  \n",
    "\n",
    "**Bed and couch**: person_bed, person_couch\n",
    "\n",
    "**Outdoor**: person_surfboard, person_elephant, person_bicycle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d2dlist = {\n",
    "    'vehicles': ['person_motorcycle', 'car_motorcycle', 'bus_truck', 'car_truck'],\n",
    "    'accessories': ['person_suitcase', 'person_umbrella'],\n",
    "    'food': ['bowl_dining_table', 'cup_dining_table', 'cake_dining_table'],\n",
    "    'appliances': ['person_oven', 'dining_table_refrigerator', 'person_refrigerator'],\n",
    "    'laptops': ['dining_table_laptop', 'couch_laptop'],\n",
    "    'beds': ['person_bed', 'person_couch'],\n",
    "    'outdoor': ['person_surfboard', 'person_elephant', 'person_bicycle']\n",
    "}\n",
    "\n",
    "d2d = {}\n",
    "for new in d2dlist:\n",
    "    for old in d2dlist[new]:\n",
    "        d2d[old] = new"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chains_train = {d: defaultdict(dict) for d in d2d.values()}\n",
    "chains_val = {d: defaultdict(dict) for d in d2d.values()}\n",
    "chains_test = {d: defaultdict(dict) for d in d2d.values()}\n",
    "\n",
    "n_utts = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "for img_path in dataset:\n",
    "    old_domain, _ = img_path.split('/')\n",
    "    \n",
    "    if old_domain not in d2d:\n",
    "        continue  # skip domains that have not been clustered\n",
    "    \n",
    "    new_domain = d2d[old_domain] \n",
    "        \n",
    "    # ----------------------------------------\n",
    "    game_ids = list(dataset[img_path].keys())\n",
    "    random.shuffle(game_ids)    \n",
    "    train, val, test = np.split(game_ids, [int(len(game_ids)*0.7), int(len(game_ids)*0.85)]) \n",
    "    # ----------------------------------------\n",
    "    \n",
    "    for game_id in dataset[img_path]:\n",
    "        if game_id in train:\n",
    "            set_name = 'train'\n",
    "            chains_train[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "        elif game_id in val:\n",
    "            set_name = 'val'\n",
    "            chains_val[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "        elif game_id in test:\n",
    "            set_name = 'test'\n",
    "            chains_test[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        n_utts[set_name][old_domain] += len(dataset[img_path][game_id])\n",
    "        n_utts[set_name][new_domain] += len(dataset[img_path][game_id])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for new in d2dlist:\n",
    "    print(new, n_utts[new])\n",
    "    for old in d2dlist[new]:\n",
    "        print(old, 'train', n_utts['train'][old], round(n_utts['train'][old] / n_utts['train'][new] * 100, 2))\n",
    "        print(old, 'val', n_utts['val'][old], round(n_utts['val'][old] / n_utts['val'][new] * 100, 2))\n",
    "        print(old, 'test', n_utts['test'][old], round(n_utts['test'][old] / n_utts['test'][new] * 100, 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "with open('../data/chains-fine-domain/train.json', 'w') as f_out:\n",
    "    json.dump(chains_train, fp=f_out, indent=2, default=str)\n",
    "    \n",
    "with open('../data/chains-fine-domain/val.json', 'w') as f_out:\n",
    "    json.dump(chains_val, fp=f_out, indent=2, default=str)\n",
    "    \n",
    "with open('../data/chains-fine-domain/test.json', 'w') as f_out:\n",
    "    json.dump(chains_test, fp=f_out, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse-grained image domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vehicles**: person_motorcycle, car_motorcycle, bus_truck, car_truck  \n",
    "\n",
    "**Outdoor**: person_suitcase, person_umbrella, person_surfboard, person_elephant, person_bicycle, person_car, person_train, person_bench, person_truck\n",
    "\n",
    "**Food**: bowl_dining_table, cup_dining_table, cake_dining_table  \n",
    "\n",
    "**Appliances**: person_oven, dining_table_refrigerator, person_refrigerator  \n",
    "\n",
    "**Indoor**: person_bed, person_couch, person_tv, couch_dining_table, person_teddy_bear, chair_couch, dining_table_laptop, couch_laptop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2dlist = {\n",
    "    'vehicles': ['person_motorcycle', 'car_motorcycle', 'bus_truck', 'car_truck'],\n",
    "    'outdoor': ['person_suitcase', 'person_umbrella', 'person_surfboard', 'person_elephant', 'person_bicycle', 'person_car', 'person_train', 'person_bench', 'person_truck'],\n",
    "    'food': ['bowl_dining_table', 'cup_dining_table', 'cake_dining_table'],\n",
    "    'appliances': ['person_oven', 'dining_table_refrigerator', 'person_refrigerator'],\n",
    "    'indoor': ['dining_table_laptop', 'couch_laptop', 'person_bed', 'person_couch', 'person_tv', 'couch_dining_table', 'person_teddy_bear', 'chair_couch']\n",
    "}\n",
    "\n",
    "d2d = {}\n",
    "for new in d2dlist:\n",
    "    for old in d2dlist[new]:\n",
    "        d2d[old] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_train = {d: defaultdict(dict) for d in d2d.values()}\n",
    "chains_val = {d: defaultdict(dict) for d in d2d.values()}\n",
    "chains_test = {d: defaultdict(dict) for d in d2d.values()}\n",
    "\n",
    "n_utts = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "for img_path in dataset:\n",
    "    old_domain, _ = img_path.split('/')\n",
    "    \n",
    "    if old_domain not in d2d:\n",
    "        continue  # skip domains that have not been clustered\n",
    "    \n",
    "    new_domain = d2d[old_domain] \n",
    "       \n",
    "    # ----------------------------------------\n",
    "    game_ids = list(dataset[img_path].keys())\n",
    "    random.shuffle(game_ids)\n",
    "    train, val, test = np.split(game_ids, [int(len(game_ids)*0.7), int(len(game_ids)*0.85)]) \n",
    "    # ----------------------------------------\n",
    "    \n",
    "    for game_id in dataset[img_path]:\n",
    "        if game_id in train:\n",
    "            set_name = 'train'\n",
    "            chains_train[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "        elif game_id in val:\n",
    "            set_name = 'val'\n",
    "            chains_val[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "        elif game_id in test:\n",
    "            set_name = 'test'\n",
    "            chains_test[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        n_utts[set_name][old_domain] += len(dataset[img_path][game_id])\n",
    "        n_utts[set_name][new_domain] += len(dataset[img_path][game_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games: 360\n",
      "Number of domains: 5\n",
      "Number of games left: 324\n",
      "outdoor 108\n",
      "6\n",
      "vehicles 48\n",
      "2\n",
      "indoor 96\n",
      "5\n",
      "food 36\n",
      "2\n",
      "appliances 36\n",
      "2\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print('Total games:', len(list(dataset.keys())))\n",
    "\n",
    "# skip domains that have not been clustered\n",
    "\n",
    "relevant_img_paths_list = []\n",
    "relevant_img_paths = defaultdict(list)\n",
    "\n",
    "for img_path in dataset:\n",
    "    old_domain, _ = img_path.split('/')\n",
    "    if old_domain not in d2d:\n",
    "        continue  # skip domains that have not been clustered\n",
    "    new_domain = d2d[old_domain] \n",
    "    if old_domain in d2d:\n",
    "        relevant_img_paths_list.append(img_path)\n",
    "        relevant_img_paths[new_domain].append(img_path)\n",
    "\n",
    "print('Number of domains:', len(relevant_img_paths))\n",
    "print('Number of games left:', sum(map(len, relevant_img_paths.values())))\n",
    "\n",
    "unseen_img_paths = []\n",
    "for d in relevant_img_paths:\n",
    "    print(d, len(relevant_img_paths[d]))\n",
    "    print(int(len(relevant_img_paths[d])*0.06))\n",
    "    random.shuffle(relevant_img_paths[d])\n",
    "    unseen_img_paths_d, _ = np.split(relevant_img_paths[d], [int(len(relevant_img_paths[d])*0.06)])\n",
    "    unseen_img_paths.extend(unseen_img_paths_d)\n",
    "\n",
    "print(len(unseen_img_paths))\n",
    "# random.shuffle(relevant_img_paths)\n",
    "\n",
    "# unseen_img_paths, _ = np.split(relevant_img_paths, [int(len(relevant_img_paths)*0.05)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #todo: split image ids within domains instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unseen_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_train = {d: defaultdict(dict) for d in d2d.values()}\n",
    "chains_val = {d: defaultdict(dict) for d in d2d.values()}\n",
    "chains_test = {d: defaultdict(dict) for d in d2d.values()}\n",
    "chains_test_unseen = {d: defaultdict(dict) for d in d2d.values()}\n",
    "chains_test_seen = {d: defaultdict(dict) for d in d2d.values()}\n",
    "\n",
    "\n",
    "n_utts = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "for img_path in relevant_img_paths_list:\n",
    "    old_domain, _ = img_path.split('/')\n",
    "    new_domain = d2d[old_domain] \n",
    "    \n",
    "    if img_path in unseen_img_paths:\n",
    "        for game_id in dataset[img_path]:\n",
    "            set_name = 'test'\n",
    "            chains_test[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "            n_utts[set_name][old_domain] += len(dataset[img_path][game_id])\n",
    "            n_utts[set_name][new_domain] += len(dataset[img_path][game_id])\n",
    "            \n",
    "            set_name ='test_unseen'\n",
    "            chains_test_unseen[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "            n_utts[set_name][old_domain] += len(dataset[img_path][game_id])\n",
    "            n_utts[set_name][new_domain] += len(dataset[img_path][game_id])\n",
    "    else:\n",
    "            \n",
    "        # ----------------------------------------\n",
    "        game_ids = list(dataset[img_path].keys())\n",
    "        random.shuffle(game_ids)\n",
    "        train, val, test = np.split(game_ids, [int(len(game_ids)*0.74), int(len(game_ids)*0.90)]) \n",
    "        # ----------------------------------------\n",
    "\n",
    "        for game_id in dataset[img_path]:\n",
    "            if game_id in train:\n",
    "                set_name = 'train'\n",
    "                chains_train[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "            elif game_id in val:\n",
    "                set_name = 'val'\n",
    "                chains_val[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "            elif game_id in test:\n",
    "                set_name = 'test'\n",
    "                chains_test[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "            else:\n",
    "                raise ValueError()\n",
    "\n",
    "            n_utts[set_name][old_domain] += len(dataset[img_path][game_id])\n",
    "            n_utts[set_name][new_domain] += len(dataset[img_path][game_id])\n",
    "            \n",
    "            if game_id in test:\n",
    "                set_name = 'test_seen'\n",
    "                chains_test_seen[new_domain][img_path][game_id] = dataset[img_path][game_id]\n",
    "                n_utts[set_name][old_domain] += len(dataset[img_path][game_id])\n",
    "                n_utts[set_name][new_domain] += len(dataset[img_path][game_id])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for new in d2dlist:\n",
    "    print(new, n_utts[new])\n",
    "    for old in d2dlist[new]:\n",
    "        print(old, 'train', n_utts['train'][old], round(n_utts['train'][old] / n_utts['train'][new] * 100, 2))\n",
    "        print(old, 'val', n_utts['val'][old], round(n_utts['val'][old] / n_utts['val'][new] * 100, 2))\n",
    "        print(old, 'test', n_utts['test'][old], round(n_utts['test'][old] / n_utts['test'][new] * 100, 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45741 45741\n"
     ]
    }
   ],
   "source": [
    "train_n, val_n, test_n, test_seen_n, test_unseen_n = 0, 0, 0, 0, 0\n",
    "for d in d2dlist:\n",
    "    train_n += n_utts['train'][d]\n",
    "    val_n += n_utts['val'][d]\n",
    "    test_n += n_utts['test'][d]\n",
    "    test_seen_n += n_utts['test_seen'][d]\n",
    "    test_unseen_n += n_utts['test_unseen'][d]\n",
    "tot = sum([train_n, val_n, test_n])\n",
    "tot2 = sum([train_n, val_n, test_seen_n, test_unseen_n])\n",
    "\n",
    "print(tot, tot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6909118733739971, 0.1525327386808334, 0.15655538794516954)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_n / tot, val_n / tot, test_n / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6909118733739971,\n",
       " 0.1525327386808334,\n",
       " 0.10380184079928292,\n",
       " 0.05275354714588662)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_n / tot, val_n / tot, test_seen_n / tot, test_unseen_n / tot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('../data/chains-coarse-domain/train.json', 'w') as f_out:\n",
    "    json.dump(chains_train, fp=f_out, indent=2, default=str)\n",
    "    \n",
    "with open('../data/chains-coarse-domain/val.json', 'w') as f_out:\n",
    "    json.dump(chains_val, fp=f_out, indent=2, default=str)\n",
    "    \n",
    "with open('../data/chains-coarse-domain/test.json', 'w') as f_out:\n",
    "    json.dump(chains_test, fp=f_out, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in d2dlist:\n",
    "    \n",
    "    with open('../data/chains-domain-specific/{}/train.json'.format(d), 'w') as f_out:\n",
    "        json.dump(chains_train[d], fp=f_out, indent=2, default=str)\n",
    "\n",
    "    with open('../data/chains-domain-specific/{}/val.json'.format(d), 'w') as f_out:\n",
    "        json.dump(chains_val[d], fp=f_out, indent=2, default=str)\n",
    "\n",
    "    with open('../data/chains-domain-specific/{}/test.json'.format(d), 'w') as f_out:\n",
    "        json.dump(chains_test[d], fp=f_out, indent=2, default=str)\n",
    "        \n",
    "    with open('../data/chains-domain-specific/{}/test_seen.json'.format(d), 'w') as f_out:\n",
    "        json.dump(chains_test_seen[d], fp=f_out, indent=2, default=str)\n",
    "        \n",
    "    with open('../data/chains-domain-specific/{}/test_unseen.json'.format(d), 'w') as f_out:\n",
    "        json.dump(chains_test_unseen[d], fp=f_out, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_dataset_train = defaultdict(dict)\n",
    "speaker_dataset_val = defaultdict(dict)\n",
    "speaker_dataset_test = defaultdict(dict)\n",
    "speaker_dataset_test_seen = defaultdict(dict)\n",
    "speaker_dataset_test_unseen = defaultdict(dict)\n",
    "\n",
    "for d in d2dlist:\n",
    "    \n",
    "    for img_path in chains_train[d]:\n",
    "        for game_id in chains_train[d][img_path]:\n",
    "            chain = chains_train[d][img_path][game_id]\n",
    "            speaker_dataset_train[img_path][game_id] = chain\n",
    "            \n",
    "    for img_path in chains_val[d]:\n",
    "        for game_id in chains_val[d][img_path]:\n",
    "            chain = chains_val[d][img_path][game_id]\n",
    "            speaker_dataset_val[img_path][game_id] = chain\n",
    "            \n",
    "    for img_path in chains_test[d]:\n",
    "        for game_id in chains_test[d][img_path]:\n",
    "            chain = chains_test[d][img_path][game_id]\n",
    "            speaker_dataset_test[img_path][game_id] = chain\n",
    "            \n",
    "    for img_path in chains_test_seen[d]:\n",
    "        for game_id in chains_test_seen[d][img_path]:\n",
    "            chain = chains_test_seen[d][img_path][game_id]\n",
    "            speaker_dataset_test_seen[img_path][game_id] = chain\n",
    "            \n",
    "    for img_path in chains_test_unseen[d]:\n",
    "        for game_id in chains_test_unseen[d][img_path]:\n",
    "            chain = chains_test_unseen[d][img_path][game_id]\n",
    "            speaker_dataset_test_unseen[img_path][game_id] = chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/chains-domain-specific/speaker/train.json'.format(d), 'w') as f_out:\n",
    "    json.dump(speaker_dataset_train, fp=f_out, indent=2, default=str)\n",
    "\n",
    "with open('../data/chains-domain-specific/speaker/val.json'.format(d), 'w') as f_out:\n",
    "    json.dump(speaker_dataset_val, fp=f_out, indent=2, default=str)\n",
    "\n",
    "with open('../data/chains-domain-specific/speaker/test.json'.format(d), 'w') as f_out:\n",
    "    json.dump(speaker_dataset_test, fp=f_out, indent=2, default=str)\n",
    "\n",
    "with open('../data/chains-domain-specific/speaker/test_seen.json'.format(d), 'w') as f_out:\n",
    "    json.dump(speaker_dataset_test_seen, fp=f_out, indent=2, default=str)\n",
    "\n",
    "with open('../data/chains-domain-specific/speaker/test_unseen.json'.format(d), 'w') as f_out:\n",
    "    json.dump(speaker_dataset_test_unseen, fp=f_out, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
