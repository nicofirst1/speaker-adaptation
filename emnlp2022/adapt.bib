@inproceedings{dathathri2020plug,
	title={{Plug and Play Language Models: A Simple Approach to Controlled Text Generation}},
	author={Sumanth Dathathri and Andrea Madotto and Janice Lan and Jane Hung and Eric Frank and Piero Molino and Jason Yosinski and Rosanne Liu},
	booktitle={International Conference on Learning Representations},
	year={2020},
	url={https://openreview.net/forum?id=H1edEyBKDS}
}

@inproceedings{nguyen2017plug,
  title={{Plug \& Play Generative Networks: Conditional Iterative Generation of Images in Latent Space}},
  author={Nguyen, Anh and Clune, Jeff and Bengio, Yoshua and Dosovitskiy, Alexey and Yosinski, Jason},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4467--4477},
  year={2017}
}

@article{keskar2019ctrl,
  title={{CTRL - A Conditional Transformer Language Model for Controllable Generation}},
  author={Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1909.05858},
  year={2019}
}

@article{ziegler2019finetuning,
  title={{Fine-Tuning Language Models from Human Preferences}},
  author={Ziegler, Daniel M. and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B. and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  url={https://arxiv.org/abs/1909.08593},
  year={2019}
}

@article{rescorla1980, 
	title={Overextension in early language development},
	volume={7},
	DOI={10.1017/S0305000900002658},
	number={2},
	journal={Journal of Child Language},
	publisher={Cambridge University Press},
	author={Rescorla, Leslie A.},
	year={1980},
	pages={321–335}
}

@article{premack1978tom,
  title={Does the chimpanzee have a theory of mind?},
  author={Premack, David and Woodruff, Guy},
  journal={Behavioral and Brain Sciences},
  volume={1},
  number={4},
  pages={515--526},
  year={1978},
  publisher={Cambridge University Press}
}

@article{brennan2009partner,
  title={Partner-specific adaptation in dialog},
  author={Brennan, Susan E and Hanna, Joy E},
  journal={Topics in Cognitive Science},
  volume={1},
  number={2},
  pages={274--291},
  year={2009},
  publisher={Wiley Online Library}
}

@inproceedings{takmaz-etal-2020-refer,
    title = "{R}efer, {R}euse, {R}educe: {G}enerating {S}ubsequent {R}eferences in {V}isual and {C}onversational {C}ontexts",
    author = "Takmaz, Ece  and
      Giulianelli, Mario  and
      Pezzelle, Sandro  and
      Sinclair, Arabella  and
      Fern{\'a}ndez, Raquel",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.353",
    doi = "10.18653/v1/2020.emnlp-main.353",
    pages = "4350--4368",
    abstract = "Dialogue participants often refer to entities or situations repeatedly within a conversation, which contributes to its cohesiveness. Subsequent references exploit the common ground accumulated by the interlocutors and hence have several interesting properties, namely, they tend to be shorter and reuse expressions that were effective in previous mentions. In this paper, we tackle the generation of first and subsequent references in visually grounded dialogue. We propose a generation model that produces referring utterances grounded in both the visual and the conversational context. To assess the referring effectiveness of its output, we also implement a reference resolution system. Our experiments and analyses show that the model produces better, more effective referring utterances than a model not grounded in the dialogue context, and generates subsequent references that exhibit linguistic patterns akin to humans.",
}

@inproceedings{corona2019modeling,
 author = {Corona Rodriguez, Rodolfo and Alaniz, Stephan and Akata, Zeynep},
  title = {{Modeling Conceptual Understanding in Image Reference Games}},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 url = {https://proceedings.neurips.cc/paper/2019/file/df308fd90635b28d82558cf580c73ed9-Paper.pdf},
 doi =
 volume = {32},
 year = {2019}
}

@InProceedings{rabinowitz2018tom,
  title = 	 {{Machine Theory of Mind}},
  author =       {Rabinowitz, Neil and Perbet, Frank and Song, Francis and Zhang, Chiyuan and Eslami, S. M. Ali and Botvinick, Matthew},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4218--4227},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/rabinowitz18a/rabinowitz18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/rabinowitz18a.html},
  abstract = 	 {Theory of mind (ToM) broadly refers to humans’ ability to represent the mental states of others, including their desires, beliefs, and intentions. We design a Theory of Mind neural network {–} a ToMnet {–} which uses meta-learning to build such models of the agents it encounters. The ToMnet learns a strong prior model for agents’ future behaviour, and, using only a small number of behavioural observations, can bootstrap to richer predictions about agents’ characteristics and mental states. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep RL agents from varied populations, and that it passes classic ToM tasks such as the "Sally-Anne" test of recognising that others can hold false beliefs about the world.}
}

@inproceedings{baker2011bayesian,
  title={{Bayesian Theory of Mind: Modeling Joint Belief-Desire Attribution}},
  author={Baker, Chris and Saxe, Rebecca and Tenenbaum, Joshua},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={33},
  number={33},
  year={2011}
}

@article{baker2017rational,
  title={Rational quantitative attribution of beliefs, desires and percepts in human mentalizing},
  author={Baker, Chris L and Jara-Ettinger, Julian and Saxe, Rebecca and Tenenbaum, Joshua B},
  journal={Nature Human Behaviour},
  volume={1},
  number={0064},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{butterfield2009tom,
  title={{Modeling Aspects of Theory of Mind with Markov Random Fields}},
  author={Butterfield, Jesse and Jenkins, Odest Chadwicke and Sobel, David M and Schwertfeger, Jonas},
  journal={International Journal of Social Robotics},
  volume={1},
  number={1},
  pages={41--51},
  year={2009},
  publisher={Springer}
}

@inproceedings{shu2019m3,
  title     = {{M3RL: Mind-aware Multi-agent Management Reinforcement Learning}},
  author    = {Tianmin Shu and Yuandong Tian},
  booktitle = {7th International Conference on Learning Representations (ICLR)},
  year      = {2019}}
}

@inproceedings{shu2018probe,
  title     = {{Interactive Agent Modeling by Learning to Probe}},
  author={Shu, Tianmin and Xiong, Caiming and Wu, Ying Nian and Zhu, Song-Chun},
  booktitle = {7th International Conference on Learning Representations (ICLR)},
  year      = {2018}}
}

@inproceedings{warnier2012robot,
	author={Warnier, Mathieu and Guitton, Julien and Lemaignan, Séverin and Alami, Rachid},  
	booktitle={2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication},   
	title={{When the robot puts itself in your shoes. Managing and exploiting human and robot beliefs}},   
	year={2012}, 
	volume={}, 
	number={}, 
	pages={948-954}, 
	doi={10.1109/ROMAN.2012.6343872}
}

@inproceedings{nakahashi2016subgoal,
author = {Nakahashi, Ryo and Baker, Chris L. and Tenenbaum, Joshua B.},
title = {{Modeling Human Understanding of Complex Intentional Action with a Bayesian Nonparametric Subgoal Model}},
year = {2016},
publisher = {AAAI Press},
abstract = {Most human behaviors consist of multiple parts, steps, or sub-tasks. These structures guide our action planning and execution, but when we observe others, the latent structure of their actions is typically unobservable, and must be inferred in order to learn new skills by demonstration, or to assist others in completing their tasks. For example, an assistant who has learned the subgoal structure of a colleague's task can more rapidly recognize and support their actions as they unfold. Here we model how humans infer subgoals from observations of complex action sequences using a nonparametric Bayesian model, which assumes that observed actions are generated by approximately rational planning over unknown subgoal sequences. We test this model with a behavioral experiment in which humans observed different series of goal-directed actions, and inferred both the number and composition of the subgoal sequences associated with each goal. The Bayesian model predicts human subgoal inferences with high accuracy, and significantly better than several alternative models and straightforward heuristics. Motivated by this result, we simulate how learning and inference of subgoals can improve performance in an artificial user assistance task. The Bayesian model learns the correct subgoals from fewer observations, and better assists users by more rapidly and accurately inferring the goal of their actions than alternative approaches.},
booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
pages = {3754–3760},
numpages = {7},
location = {Phoenix, Arizona},
series = {AAAI'16}
}

@inproceedings{finn2017meta,
author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
title = {{Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}},
year = {2017},
publisher = {JMLR.org},
abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {1126–1135},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}

@inproceedings{huang2021adaptation,
    title = "{{User Factor Adaptation for User Embedding via Multitask Learning}}",
    author = "Huang, Xiaolei  and
      Paul, Michael J.  and
      Dernoncourt, Franck  and
      Burke, Robin  and
      Dredze, Mark",
    booktitle = "Proceedings of the Second Workshop on Domain Adaptation for NLP",
    month = apr,
    year = "2021",
    address = "Kyiv, Ukraine",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2021.adaptnlp-1.18",
    pages = "172--182",
    abstract = "Language varies across users and their interested fields in social media data: words authored by a user across his/her interests may have different meanings (e.g., cool) or sentiments (e.g., fast). However, most of the existing methods to train user embeddings ignore the variations across user interests, such as product and movie categories (e.g., drama vs. action). In this study, we treat the user interest as domains and empirically examine how the user language can vary across the user factor in three English social media datasets. We then propose a user embedding model to account for the language variability of user interests via a multitask learning framework. The model learns user language and its variations without human supervision. While existing work mainly evaluated the user embedding by extrinsic tasks, we propose an intrinsic evaluation via clustering and evaluate user embeddings by an extrinsic task, text classification. The experiments on the three English-language social media datasets show that our proposed approach can generally outperform baselines via adapting the user factor.",
}

@article{hawkins2021division,
author = {Hawkins, Robert D. and Gweon, Hyowon and Goodman, Noah D.},
title = {{The Division of Labor in Communication: Speakers Help Listeners Account for Asymmetries in Visual Perspective}},
journal = {Cognitive Science},
volume = {45},
number = {3},
pages = {e12926},
year = {2021},
keywords = {Theory of mind, Pragmatics, Resource rationality, Communication},
doi = {https://doi.org/10.1111/cogs.12926},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12926},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12926},
abstract = {Recent debates over adults' theory of mind use have been fueled by surprising failures of perspective-taking in communication, suggesting that perspective-taking may be relatively effortful. Yet adults routinely engage in effortful processes when needed. How, then, should speakers and listeners allocate their resources to achieve successful communication? We begin with the observation that the shared goal of communication induces a natural division of labor: The resources one agent chooses to allocate toward perspective-taking should depend on their expectations about the other's allocation. We formalize this idea in a resource-rational model augmenting recent probabilistic weighting accounts with a mechanism for (costly) control over the degree of perspective-taking. In a series of simulations, we first derive an intermediate degree of perspective weighting as an optimal trade-off between expected costs and benefits of perspective-taking. We then present two behavioral experiments testing novel predictions of our model. In Experiment 1, we manipulated the presence or absence of occlusions in a director–matcher task. We found that speakers spontaneously modulated the informativeness of their descriptions to account for “known unknowns” in their partner's private view, reflecting a higher degree of speaker perspective-taking than previously acknowledged. In Experiment 2, we then compared the scripted utterances used by confederates in prior work with those produced in interactions with unscripted directors. We found that confederates were systematically less informative than listeners would initially expect given the presence of occlusions, but listeners used violations to adaptively make fewer errors over time. Taken together, our work suggests that people are not simply “mindblind”; they use contextually appropriate expectations to navigate the division of labor with their partner. We discuss how a resource-rational framework may provide a more deeply explanatory foundation for understanding flexible perspective-taking under processing constraints.}
}

@inproceedings{hawkins2020continual,
    title = "{{Continual Adaptation for Efficient Machine Communication}}",
    author = "Hawkins, Robert  and
      Kwon, Minae  and
      Sadigh, Dorsa  and
      Goodman, Noah",
    booktitle = "Proceedings of the 24th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.conll-1.33",
    doi = "10.18653/v1/2020.conll-1.33",
    pages = "408--419",
    abstract = "To communicate with new partners in new contexts, humans rapidly form new linguistic conventions. Recent neural language models are able to comprehend and produce the existing conventions present in their training data, but are not able to flexibly and interactively adapt those conventions on the fly as humans do. We introduce an interactive repeated reference task as a benchmark for models of adaptation in communication and propose a regularized continual learning framework that allows an artificial agent initialized with a generic language model to more accurately and efficiently communicate with a partner over time. We evaluate this framework through simulations on COCO and in real-time reference game experiments with human partners.",
}

@article{hawkins2020characterizing,
  title={{Characterizing the Dynamics of Learning in Repeated Reference Games}},
  author={Hawkins, Robert D and Frank, Michael C and Goodman, Noah D},
  journal={Cognitive Science},
  volume={44},
  number={6},
  pages={e12845},
  year={2020},
  publisher={Wiley Online Library}
}

@inproceedings{shore-skantze-2018-using,
    title = "Using Lexical Alignment and Referring Ability to Address Data Sparsity in Situated Dialog Reference Resolution",
    author = "Shore, Todd  and
      Skantze, Gabriel",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1252",
    doi = "10.18653/v1/D18-1252",
    pages = "2288--2297",
    abstract = "Referring to entities in situated dialog is a collaborative process, whereby interlocutors often expand, repair and/or replace referring expressions in an iterative process, converging on conceptual pacts of referring language use in doing so. Nevertheless, much work on exophoric reference resolution (i.e. resolution of references to entities outside of a given text) follows a literary model, whereby individual referring expressions are interpreted as unique identifiers of their referents given the state of the dialog the referring expression is initiated. In this paper, we address this collaborative nature to improve dialogic reference resolution in two ways: First, we trained a words-as-classifiers logistic regression model of word semantics and incrementally adapt the model to idiosyncratic language between dyad partners during evaluation of the dialog. We then used these semantic models to learn the general referring ability of each word, which is independent of referent features. These methods facilitate accurate automatic reference resolution in situated dialog without annotation of referring expressions, even with little background data.",
}

@inproceedings{roy-etal-2019-leveraging,
    title = "Leveraging Past References for Robust Language Grounding",
    author = "Roy, Subhro  and
      Noseworthy, Michael  and
      Paul, Rohan  and
      Park, Daehyung  and
      Roy, Nicholas",
    booktitle = "Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/K19-1040",
    doi = "10.18653/v1/K19-1040",
    pages = "430--440",
    abstract = "Grounding referring expressions to objects in an environment has traditionally been considered a one-off, ahistorical task. However, in realistic applications of grounding, multiple users will repeatedly refer to the same set of objects. As a result, past referring expressions for objects can provide strong signals for grounding subsequent referring expressions. We therefore reframe the grounding problem from the perspective of coreference detection and propose a neural network that detects when two expressions are referring to the same object. The network combines information from vision and past referring expressions to resolve which object is being referred to. Our experiments show that detecting referring expression coreference is an effective way to ground objects described by subtle visual properties, which standard visual grounding models have difficulty capturing. We also show the ability to detect object coreference allows the grounding model to perform well even when it encounters object categories not seen in the training data.",
}

@ARTICLE{DaleReiter95,
  author = {Robert Dale and Ehud Reiter},
  title = {Computational Interpretations of the {Gricean Maxims} in the {Generation
	of Referring Expressions}},
  journal = {Cognitive Science},
  year = {1995},
  volume = {18},
  pages = {233--266},
  owner = {raquel},
  timestamp = {2013.05.19}
}

@inproceedings{cohn-gordon-etal-2018-pragmatically,
    title = "Pragmatically Informative Image Captioning with Character-Level Inference",
    author = "Cohn-Gordon, Reuben  and
      Goodman, Noah  and
      Potts, Christopher",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-2070",
    doi = "10.18653/v1/N18-2070",
    pages = "439--443",
    abstract = "We combine a neural image captioner with a Rational Speech Acts (RSA) model to make a system that is pragmatically informative: its objective is to produce captions that are not merely true but also distinguish their inputs from similar images. Previous attempts to combine RSA with neural image captioning require an inference which normalizes over the entire set of possible utterances. This poses a serious problem of efficiency, previously solved by sampling a small subset of possible utterances. We instead solve this problem by implementing a version of RSA which operates at the level of characters ({``}a{''}, {``}b{''}, {``}c{''}, ...) during the unrolling of the caption. We find that the utterance-level effect of referential captions can be obtained with only character-level decisions. Finally, we introduce an automatic method for testing the performance of pragmatic speaker models, and show that our model outperforms a non-pragmatic baseline as well as a word-level RSA captioner.",
}

@inproceedings{vedantam2017context,
  title={Context-aware captions from context-agnostic supervision},
  author={Vedantam, Ramakrishna and Bengio, Samy and Murphy, Kevin and Parikh, Devi and Chechik, Gal},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={251--260},
  year={2017}
}

@inproceedings{mao2016generation,
  title={Generation and comprehension of unambiguous object descriptions},
  author={Mao, Junhua and Huang, Jonathan and Toshev, Alexander and Camburu, Oana and Yuille, Alan L and Murphy, Kevin},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={11--20},
  year={2016}
}



@inproceedings{das2017visual,
	title={Visual dialog},
	author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={326--335},
	url={http://openaccess.thecvf.com/content_cvpr_2017/papers/Das_Visual_Dialog_CVPR_2017_paper.pdf},
	year={2017}
}


@inproceedings{agarwal2020history,
	title={History for Visual Dialog: Do we really need it?},
	author={Agarwal, Shubham and Bui, Trung and Lee, Joon-Young and Konstas, Ioannis and Rieser, Verena},
	booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	note={To appear},
	url={https://arxiv.org/pdf/2005.07493.pdf},
	year={2020}
}


@inproceedings{massiceti2018,
	title={Visual Dialogue Without Vision Or Dialogue},
	author={Massiceti, Daniela and Dokania, Puneet K. and Siddharth, N and Torr, Philip H. S.},
	booktitle={NeurIPS Workshop On Critiquing And Correcting Trends In Machine Learning},
	url={https://arxiv.org/pdf/1812.06417.pdf},
	year={2018}
}

@article{Yang2019MakingHM,
	title={Making History Matter: History-Advantage Sequence Training for Visual Dialog},
	author={Tianhao Yang and Zheng-Jun Zha and Hanwang Zhang},
	journal={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
	year={2019},
	url={http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Making_History_Matter_History-Advantage_Sequence_Training_for_Visual_Dialog_ICCV_2019_paper.pdf},
	pages={2561-2569}
}

@inproceedings{de2017guesswhat,
	title={{GuessWhat?! Visual object discovery through multi-modal dialogue}},
	author={De Vries, Harm and Strub, Florian and Chandar, Sarath and Pietquin, Olivier and Larochelle, Hugo and Courville, Aaron},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={5503--5512},
	url={http://openaccess.thecvf.com/content_cvpr_2017/papers/de_Vries_GuessWhat_Visual_Object_CVPR_2017_paper.pdf},
	year={2017}
}

@inproceedings{chattopadhyay2017evaluating,
	title={{Evaluating visual conversational agents via cooperative human-AI games}},
	author={Chattopadhyay, Prithvijit and Yadav, Deshraj and Prabhu, Viraj and Chandrasekaran, Arjun and Das, Abhishek and Lee, Stefan and Batra, Dhruv and Parikh, Devi},
	booktitle={Fifth AAAI Conference on Human Computation and Crowdsourcing},
	url={https://www.aaai.org/ocs/index.php/HCOMP/HCOMP17/paper/download/15936/15257},
	year={2017}
}

@inproceedings{haber2019photobook,
	title={The {PhotoBook} Dataset: Building Common Ground through Visually-Grounded Dialogue},
	author={Haber, Janosch and Baumg{\"a}rtner, Tim and Takmaz, Ece and Gelderloos, Lieke and Bruni, Elia and Fern{\'a}ndez, Raquel},
	booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	pages={1895--1910},
	url={https://www.aclweb.org/anthology/P19-1184.pdf},
	year={2019}
}

@inproceedings{lin2014coco,
  title="{Microsoft COCO: Common Objects in Context}",
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{krishna2017visual,
  title="{Visual Genome: Connecting Language and Vision using Crowdsourced Dense Image Annotations}",
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International Journal of Computer Vision},
  volume={123},
  number={1},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{bert-score,
  title="{BERTScore: Evaluating Text Generation with BERT}",
  author={Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=SkeHuCVFDr}
}

@inproceedings{banerjee2005meteor,
  title="{METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments}",
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the ACL workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{jaeger2007speakers,
	author    = {Roger Levy and
	T. Florian Jaeger},
	editor    = {Bernhard Sch{\"{o}}lkopf and
	John C. Platt and
	Thomas Hofmann},
	title     = {Speakers optimize information density through syntactic reduction},
	booktitle = {Advances in Neural Information Processing Systems 19, Proceedings
	of the Twentieth Annual Conference on Neural Information Processing
	Systems, Vancouver, British Columbia, Canada, December 4-7, 2006},
	pages     = {849--856},
	publisher = {{MIT} Press},
	year      = {2006},
	url       = {http://papers.nips.cc/paper/3129-speakers-optimize-information-density-through-syntactic-reduction},
	timestamp = {Fri, 06 Mar 2020 17:00:33 +0100},
	biburl    = {https://dblp.org/rec/conf/nips/LevyJ06.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{keller-2004-entropy,
    title = "The Entropy Rate Principle as a Predictor of Processing Effort: An Evaluation against Eye-tracking Data",
    author = "Keller, Frank",
    booktitle = "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W04-3241",
    pages = "317--324",
}

@inproceedings{genzel-charniak-2002-entropy,
    title = "Entropy Rate Constancy in Text",
    author = "Genzel, Dmitriy  and
      Charniak, Eugene",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P02-1026",
    doi = "10.3115/1073083.1073117",
    pages = "199--206",
}

@article{BrennanClark1996,
	Author = {Susan E. Brennan and Herbert H. Clark},
	Journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	Pages = {1482--1493},
	Title = {Conceptual pacts and lexical choice in conversation},
	Volume = {22},
	Year = {1996}}

@book{Clark1996,
	Author = {Clark, Herbert H.},
	Place = {Cambridge},
	Publisher = {Cambridge University Press},
	Title = {Using Language},
	Year = {1996}
}

@article{ClarkWilkes-Gibbs1986,
	Author = {Herbert H. Clark and Deanna Wilkes-Gibbs},
	Doi = {https://doi.org/10.1016/0010-0277(86)90010-7},
	File = {:Clark1986.pdf:PDF},
	Issn = {0010-0277},
	Journal = {Cognition},
	Number = {1},
	Pages = {1 - 39},
	Title = {Referring as a collaborative process},
	Url = {http://www.sciencedirect.com/science/article/pii/0010027786900107},
	Volume = {22},
	Year = {1986}
}

@inproceedings{andreas-klein-2016-reasoning,
	title = "Reasoning about Pragmatics with Neural Listeners and Speakers",
	author = "Andreas, Jacob  and
	Klein, Dan",
	booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
	month = nov,
	year = "2016",
	address = "Austin, Texas",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D16-1125",
	doi = "10.18653/v1/D16-1125",
	pages = "1173--1182",
}

@article{bernardi2016automatic,
	title={Automatic description generation from images: A survey of models, datasets, and evaluation measures},
	author={Bernardi, Raffaella and Cakici, Ruket and Elliott, Desmond and Erdem, Aykut and Erdem, Erkut and Ikizler-Cinbis, Nazli and Keller, Frank and Muscat, Adrian and Plank, Barbara},
	journal={Journal of Artificial Intelligence Research},
	volume={55},
	pages={409--442},
	year={2016}
}

@article{GarrodAnderson1987,
	Author = {Simon Garrod and Anthony Anderson},
	Issn = {0010-0277},
	Journal = {Cognition},
	Number = {2},
	Pages = {181 - 218},
	Title = {Saying what you mean in dialogue: A study in conceptual and semantic co-ordination},
	Url = {http://www.sciencedirect.com/science/article/pii/0010027787900187},
	Volume = {27},
	Year = {1987}
	}



@article{Pickering2004-PICTAM,
	volume = {27},
	year = {2004},
	author = {Martin J. Pickering and Simon Garrod},
	number = {2},
	pages = {169--190},
	title = {Toward a Mechanistic Psychology of Dialogue},
	journal = {Behavioral and Brain Sciences}
}


@inproceedings{visdial_diversity,
	title={Improving Generative Visual Dialog by Answering Diverse Questions},
	author={Vishvak Murahari and Prithvijit Chattopadhyay and Dhruv Batra and Devi Parikh and Abhishek Das},
	booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	year={2019}
}

@inproceedings{van2006building,
	Author = {van Deemter, Kees and van der Sluis, Ielka and Gatt, Albert},
	Booktitle = {Proceedings of the Fourth International Natural Language Generation Conference},
	Organization = {Association for Computational Linguistics},
	Pages = {130--132},
	Title = {Building a semantically transparent corpus for the generation of referring expressions},
	Year = {2006}
}

@inproceedings{viethen2011gre3d7,
	Author = {Viethen, Jette and Dale, Robert},
	Booktitle = {Proceedings of the UCNLG+ Eval: Language generation and evaluation workshop},
	Organization = {Association for Computational Linguistics},
	Pages = {12--22},
	Title = {{GRE3D7: A corpus of distinguishing descriptions for objects in visual scenes}},
	Year = {2011}
}

@inproceedings{mitchell2013typicality,
	Author = {Mitchell, Margaret and Reiter, Ehud and Van Deemter, Kees},
	Booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	Title = {Typicality and object reference},
	Volume = {35},
	Year = {2013}}

@inproceedings{mitchell2013generating,
	Author = {Mitchell, Margaret and Van Deemter, Kees and Reiter, Ehud},
	Booktitle = {Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics},
	Organization = {Association for Computational Linguistics (ACL)},
	Title = {Generating expressions that refer to visible objects},
	Year = {2013}}

@inproceedings{kazemzadeh2014referitgame,
	title={{ReferItGame: Referring to objects in photographs of natural scenes}},
	author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara},
	booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
	pages={787--798},
	year={2014}
}

@inproceedings{lu2019vilbert,
	title={{ViLBERT: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks}},
	author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
	booktitle={Advances in Neural Information Processing Systems},
	pages={13--23},
	year={2019}
}

@inproceedings{goudbeek-krahmer-2010-preferences,
    title = "Preferences versus Adaptation during Referring Expression Generation",
    author = "Goudbeek, Martijn  and
      Krahmer, Emiel",
    booktitle = "Proceedings of the {ACL} 2010 Conference Short Papers",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P10-2011",
    pages = "55--59",
}

@inproceedings{buschmeier-etal-2009-alignment,
    title = "An Alignment-Capable Microplanner for {N}atural {L}anguage {G}eneration",
    author = "Buschmeier, Hendrik  and
      Bergmann, Kirsten  and
      Kopp, Stefan",
    booktitle = "Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009)",
    month = mar,
    year = "2009",
    address = "Athens, Greece",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W09-0612",
    pages = "82--89",
}

@inproceedings{janarthanam-lemon-2009-learning,
    title = "Learning Lexical Alignment Policies for Generating Referring Expressions for Spoken Dialogue Systems",
    author = "Janarthanam, Srinivasan  and
      Lemon, Oliver",
    booktitle = "Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009)",
    month = mar,
    year = "2009",
    address = "Athens, Greece",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W09-0611",
    pages = "74--81",
}

@article{branigan2010linguistic,
  title={Linguistic alignment between people and computers},
  author={Branigan, Holly P and Pickering, Martin J and Pearson, Jamie and McLean, Janet F},
  journal={Journal of pragmatics},
  volume={42},
  number={9},
  pages={2355--2368},
  year={2010},
  publisher={Elsevier}
}

@article{goudbeek2012alignment,
  title={Alignment in interactive reference production: Content planning, modifier ordering, and referential overspecification.},
  author={Goudbeek, Martijn and Krahmer, Emiel},
  journal={Topics in Cognitive Science},
  year={2012},
  publisher={Wiley-Blackwell Publishing Ltd.}
}

@inproceedings{Papineni:2002,
	Acmid = {1073135},
	Author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
	Booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
	Date-Modified = {2019-12-02 10:55:56 +0100},
	Doi = {10.3115/1073083.1073135},
	Location = {Philadelphia, Pennsylvania},
	Numpages = {8},
	Pages = {311--318},
	Publisher = {Association for Computational Linguistics},
	Title = {{BLEU}: A Method for Automatic Evaluation of Machine Translation},
	Url = {https://doi.org/10.3115/1073083.1073135},
	Year = {2002},
	Bdsk-Url-1 = {https://doi.org/10.3115/1073083.1073135}}

@inproceedings{Lin2004,
	Address = {Barcelona, Spain},
	Author = {Lin, Chin-Yew},
	Booktitle = {Text Summarization Branches Out},
	Month = jul,
	Pages = {74--81},
	Publisher = {Association for Computational Linguistics},
	Title = {{ROUGE}: A Package for Automatic Evaluation of Summaries},
	Url = {https://www.aclweb.org/anthology/W04-1013},
	Year = {2004}}



@inproceedings{cider,
	title={Cider: Consensus-based image description evaluation},
	author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
	booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={4566--4575},
	url={https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.pdf},
	year={2015}
}

@inproceedings{dusek-jurcicek-2016-context,
    title = "A Context-aware Natural Language Generator for Dialogue Systems",
    author = "Du{\v{s}}ek, Ond{\v{r}}ej  and
      Jur{\v{c}}{\'\i}{\v{c}}ek, Filip",
    booktitle = "Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = sep,
    year = "2016",
    address = "Los Angeles",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W16-3622",
    doi = "10.18653/v1/W16-3622",
    pages = "185--190",
}

@article{lopes2015rule,
  title={From rule-based to data-driven lexical entrainment models in spoken dialog systems},
  author={Lopes, Jos{\'e} and Eskenazi, Maxine and Trancoso, Isabel},
  journal={Computer Speech \& Language},
  volume={31},
  number={1},
  pages={87--112},
  year={2015},
  publisher={Elsevier}
}

@inproceedings{brockmann2005modelling,
  title={Modelling alignment for affective dialogue},
  author={Brockmann, Carsten and Isard, Amy and Oberlander, Jon and White, Michael},
  booktitle={Workshop on adapting the interaction style to affective factors at the 10th international conference on user modeling (UM-05)},
  year={2005}
}

@inproceedings{stoyanchev-stent-2009-lexical,
    title = "Lexical and Syntactic Adaptation and Their Impact in Deployed Spoken Dialog Systems",
    author = "Stoyanchev, Svetlana  and
      Stent, Amanda",
    booktitle = "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",
    month = jun,
    year = "2009",
    address = "Boulder, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N09-2048",
    pages = "189--192",
}

@incollection{hu2016entrainment,
  title={Entrainment in Pedestrian Direction Giving: How many kinds of entrainment?},
  author={Hu, Zhichao and Halberg, Gabrielle and Jimenez, Carolynn R and Walker, Marilyn A},
  booktitle={Situated Dialog in Speech-Based Human-Computer Interaction},
  pages={151--164},
  year={2016},
  publisher={Springer}
}

@inproceedings{sankar-etal-2019-neural,
    title = "Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study",
    author = "Sankar, Chinnadhurai  and
      Subramanian, Sandeep  and
      Pal, Chris  and
      Chandar, Sarath  and
      Bengio, Yoshua",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1004",
    doi = "10.18653/v1/P19-1004",
    pages = "32--37",
    abstract = "Neural generative models have been become increasingly popular when building conversational agents. They offer flexibility, can be easily adapted to new domains, and require minimal domain engineering. A common criticism of these systems is that they seldom understand or use the available dialog history effectively. In this paper, we take an empirical approach to understanding how these models use the available dialog history by studying the sensitivity of the models to artificially introduced unnatural changes or perturbations to their context at test time. We experiment with 10 different types of perturbations on 4 multi-turn dialog datasets and find that commonly used neural dialog architectures like recurrent and transformer-based seq2seq models are rarely sensitive to most perturbations such as missing or reordering utterances, shuffling words, etc. Also, by open-sourcing our code, we believe that it will serve as a useful diagnostic tool for evaluating dialog systems in the future.",
}

@inproceedings{devlin-etal-2019-bert,
	title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
	author = "Devlin, Jacob  and
	Chang, Ming-Wei  and
	Lee, Kenton  and
	Toutanova, Kristina",
	booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/N19-1423",
	doi = "10.18653/v1/N19-1423",
	pages = "4171--4186",
	abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}


@article{Wolf2019HuggingFacesTS,
	title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
	author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R\'emi Louf and Morgan Funtowicz and Jamie Brew},
	journal={ArXiv},
	year={2019},
	volume={abs/1910.03771}
}

@article{10.1162/neco.1997.9.8.1735,
	author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
	title = {Long Short-Term Memory},
	year = {1997},
	issue_date = {November 15, 1997},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
	volume = {9},
	number = {8},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	journal = {Neural Comput.},
	month = nov,
	pages = {1735–1780},
	numpages = {46}
}

@article{resnet2016,
	title={{Deep Residual Learning for Image Recognition}},
	author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year={2016},
	pages={770-778}
}


@inproceedings{imagenet_cvpr09,
	title={{ImageNet: A Large-Scale Hierarchical Image Database}},
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
	pages={248--255},
	year={2009},
	organization={IEEE}
}

@inproceedings{relu,
	author = {Nair, Vinod and Hinton, Geoffrey E.},
	title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
	year = {2010},
	isbn = {9781605589077},
	publisher = {Omnipress},
	address = {Madison, WI, USA},
	booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
	pages = {807--814},
	numpages = {8},
	location = {Haifa, Israel},
	series = {ICML'10}
}

@inproceedings{GTTP,
	title = "Get To The Point: Summarization with Pointer-Generator Networks",
	author = "See, Abigail  and
	Liu, Peter J.  and
	Manning, Christopher D.",
	booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2017",
	address = "Vancouver, Canada",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P17-1099",
	doi = "10.18653/v1/P17-1099",
	pages = "1073--1083",
	abstract = "Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.",
}

@inproceedings{Adam,
	author    = {Diederik P. Kingma and
	Jimmy Ba},
	editor    = {Yoshua Bengio and
	Yann LeCun},
	title     = {Adam: {A} Method for Stochastic Optimization},
	booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
	San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
	year      = {2015},
	url       = {http://arxiv.org/abs/1412.6980},
	timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{tan-bansal-2019-lxmert,
	title = "{LXMERT}: Learning Cross-Modality Encoder Representations from Transformers",
	author = "Tan, Hao  and
	Bansal, Mohit",
	booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
	month = nov,
	year = "2019",
	address = "Hong Kong, China",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D19-1514",
	doi = "10.18653/v1/D19-1514",
	pages = "5100--5111",
	abstract = "Vision-and-language reasoning requires an understanding of visual concepts, language semantics, and, most importantly, the alignment and relationships between these two modalities. We thus propose the LXMERT (Learning Cross-Modality Encoder Representations from Transformers) framework to learn these vision-and-language connections. In LXMERT, we build a large-scale Transformer model that consists of three encoders: an object relationship encoder, a language encoder, and a cross-modality encoder. Next, to endow our model with the capability of connecting vision and language semantics, we pre-train the model with large amounts of image-and-sentence pairs, via five diverse representative pre-training tasks: masked language modeling, masked object prediction (feature regression and label classification), cross-modality matching, and image question answering. These tasks help in learning both intra-modality and cross-modality relationships. After fine-tuning from our pre-trained parameters, our model achieves the state-of-the-art results on two visual question answering datasets (i.e., VQA and GQA). We also show the generalizability of our pre-trained cross-modality model by adapting it to a challenging visual-reasoning task, NLVR2, and improve the previous best result by 22{\%} absolute (54{\%} to 76{\%}). Lastly, we demonstrate detailed ablation studies to prove that both our novel model components and pre-training strategies significantly contribute to our strong results. Code and pre-trained models publicly available at: https://github.com/airsplay/lxmert",
}


@article{KraussWeinheimer1967,
	Address = {Netherlands},
	Author = {Krauss, Robert M. and Weinheimer, Sidney},
	Doi = {10.1016/S0022-5371(67)80125-7},
	Issn = {0022-5371(Print)},
	Journal = {Journal of Verbal Learning \& Verbal Behavior},
	Number = {3},
	Pages = {359--363},
	Publisher = {Elsevier Science},
	Title = {Effect of referent similarity and communication mode on verbal encoding.},
	Volume = {6},
	Year = {1967}
}

@article{brysbaert2014concreteness,
  title={Concreteness ratings for 40 thousand generally known English word lemmas},
  author={Brysbaert, Marc and Warriner, Amy Beth and Kuperman, Victor},
  journal={Behavior research methods},
  volume={46},
  number={3},
  pages={904--911},
  year={2014},
  publisher={Springer}
}

@article{krahmer-van-deemter-2012-computational,
    title = "Computational Generation of Referring Expressions: A Survey",
    author = "Krahmer, Emiel  and
      van Deemter, Kees",
    journal = "Computational Linguistics",
    volume = "38",
    number = "1",
    year = "2012",
    url = "https://www.aclweb.org/anthology/J12-1006",
    doi = "10.1162/COLI_a_00088",
    pages = "173--218",
}

@article{jordan2005learning,
  title={Learning content selection rules for generating object descriptions in dialogue},
  author={Jordan, Pamela W and Walker, Marilyn A},
  journal={Journal of Artificial Intelligence Research},
  volume={24},
  pages={157--194},
  year={2005}
}

@inproceedings{viethen-etal-2011-generating,
    title = "Generating Subsequent Reference in Shared Visual Scenes: Computation vs Re-Use",
    author = "Viethen, Jette  and
      Dale, Robert  and
      Guhe, Markus",
    booktitle = "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2011",
    address = "Edinburgh, Scotland, UK.",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D11-1107",
    pages = "1158--1167",
}

@inproceedings{mcdonald-1978-subsequent-reference,
    title = "Subsequent Reference: Syntactic and Rhetorical Constraints",
    author = "McDonald, David D.",
    booktitle = "Theoretical Issues in Natural Language Processing-2",
    year = "1978",
    url = "https://www.aclweb.org/anthology/T78-1009",
}

@inproceedings{gupta2005automatic,
  title={Automatic evaluation of referring expression generation using corpora},
  author={Gupta, Surabhi and Stent, Amanda},
  booktitle={Proceedings of the Workshop on Using Corpora for Natural Language Generation},
  pages={1--6},
  year={2005}
}

@phdthesis{jordan2000intentional,
  title={Intentional Influences on Object Redescriptions in Dialogue: Evidence from an Empirical Study},
  author={Jordan, Pamela W},
  year={2000},
  school={University of Pittsburgh}
}

@inproceedings{stoia-etal-2006-noun,
    title = "Noun Phrase Generation for Situated Dialogs",
    author = "Stoia, Laura  and
      Shockley, Darla Magdalene  and
      Byron, Donna K.  and
      Fosler-Lussier, Eric",
    booktitle = "Proceedings of the Fourth International Natural Language Generation Conference",
    month = jul,
    year = "2006",
    address = "Sydney, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W06-1412",
    pages = "81--88",
}

@inproceedings{yu2019deep,
  title={Deep modular co-attention networks for visual question answering},
  author={Yu, Zhou and Yu, Jun and Cui, Yuhao and Tao, Dacheng and Tian, Qi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6281--6290},
  year={2019}
}

@inproceedings{serban2017hierarchical,
  title={A hierarchical latent variable encoder-decoder model for generating dialogues},
  author={Serban, Iulian Vlad and Sordoni, Alessandro and Lowe, Ryan and Charlin, Laurent and Pineau, Joelle and Courville, Aaron and Bengio, Yoshua},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{bordes2017learning,
  title={Learning End-to-End Goal-Oriented Dialog},
  author={Bordes, Antoine and Boureau, Y-Lan and Weston, Jason},
  year={2017},
  booktitle={International Conference on Learning Representations}
}

@article{downing1977,
	ISSN = {00978507, 15350665},
	URL = {http://www.jstor.org/stable/412913},
	author = {Pamela Downing},
	journal = {Language},
	number = {4},
	pages = {810--842},
	publisher = {Linguistic Society of America},
	title = {On the Creation and Use of English Compound Nouns},
	volume = {53},
	year = {1977}
}

@article{costello2000efficient,
	title={Efficient creativity: Constraint-guided conceptual combination},
	author={Costello, Fintan J and Keane, Mark T},
	journal={Cognitive Science},
	volume={24},
	number={2},
	pages={299--349},
	year={2000},
	publisher={Wiley Online Library}
}

@inproceedings{Sutskever,
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	title = {Sequence to Sequence Learning with Neural Networks},
	year = {2014},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
	booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
	pages = {3104--3112},
	numpages = {9},
	location = {Montreal, Canada},
	series = {NIPS'14}
}

@inproceedings{Bahdanau,
	author    = {Dzmitry Bahdanau and
	Felix Hill and
	Jan Leike and
	Edward Hughes and
	Pushmeet Kohli and
	Edward Grefenstette},
	title     = {Jointly Learning "What" and "How" from Instructions and Goal-States},
	booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
	Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings},
	publisher = {OpenReview.net},
	year      = {2018},
	url       = {https://openreview.net/forum?id=BkmZvdkPM},
	timestamp = {Thu, 04 Apr 2019 13:20:09 +0200},
	biburl    = {https://dblp.org/rec/conf/iclr/BahdanauHLHKG18.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{Yu2017AJS,
	title={A Joint Speaker-Listener-Reinforcer Model for Referring Expressions},
	author={Licheng Yu and Hao Tan and Mohit Bansal and Tamara L. Berg},
	journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year={2017},
	pages={3521-3529}
}

@inproceedings{liu-etal-2016-evaluate,
	title = "How {NOT} To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation",
	author = "Liu, Chia-Wei  and
	Lowe, Ryan  and
	Serban, Iulian  and
	Noseworthy, Mike  and
	Charlin, Laurent  and
	Pineau, Joelle",
	booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
	month = nov,
	year = "2016",
	address = "Austin, Texas",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D16-1230",
	doi = "10.18653/v1/D16-1230",
	pages = "2122--2132",
}

@article{shannon1948mathematical,
  title={{A mathematical theory of communication, Bell System Technical Journal 27: 379-423 and 623--659}},
  author={Claude E. Shannon},
  journal={Mathematical Reviews (MathSciNet): MR10, 133e},
  year={1948}
}


@article{xu2018information,
  title={Information density converges in dialogue: Towards an information-theoretic model},
  author={Xu, Yang and Reitter, David},
  journal={Cognition},
  volume={170},
  pages={147--163},
  year={2018},
  publisher={Elsevier}
}

@article{concreteness1975richardson,
author = {John T. E. Richardson},
title ={Concreteness and Imageability},
journal = {Quarterly Journal of Experimental Psychology},
volume = {27},
number = {2},
pages = {235-249},
year = {1975},
doi = {10.1080/14640747508400483},

URL = {
        https://doi.org/10.1080/14640747508400483

},
eprint = {
        https://doi.org/10.1080/14640747508400483

}
,
    abstract = { Previous research has shown that the positive effect of imageability upon recall is confined to abstract items. In Experiment I it was found that imageability would affect the recall of concrete items if subjects were instructed to use imagery in their memorizing. This suggested that imagery is not usually employed in remembering concrete items. In Experiment II subjects were asked to categorize items on the basis of their meaning. A majority showed sorting related to the concreteness of the items, but very few showed sorting related to imageability. In Experiment III it was found that the concreteness of an item correlated with the time taken to produce a free associate to it, but that its imageability did not. It was concluded that concreteness is a feature of lexical organization, and not a measure of the image-arousing quality of verbal material. }
}

@article{metzing2003conceptual,
  title={When conceptual pacts are broken: Partner-specific effects on the comprehension of referring expressions},
  author={Metzing, Charles and Brennan, Susan E},
  journal={Journal of Memory and Language},
  volume={49},
  number={2},
  pages={201--213},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{loper2002nltk,
	title={NLTK: The Natural Language Toolkit},
	author={Loper, Edward and Bird, Steven},
	booktitle={Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics},
	pages={63--70},
	year={2002}
}

@INCOLLECTION{Grice75,
  author = {H. Paul Grice},
  title = {Logic and Conversation},
  booktitle = {The Logic of Grammar},
  publisher = {Dickenson},
  year = {1975},
  editor = {D. Davidson and G. Harman},
  pages = {64--75},
  address = {Encino, California},
  owner = {raquel},
  timestamp = {2010.02.09}
}

@article{stalnaker2002common,
  title={Common ground},
  author={Stalnaker, Robert},
  journal={Linguistics and philosophy},
  volume={25},
  number={5/6},
  pages={701--721},
  year={2002}
}

@incollection{clark1991grounding,
  title={Grounding in communication},
  author={Clark, Herbert H. and Brennan, Susan E.},
  booktitle={Perspectives on socially shared cognition},
  pages={127--149},
  year={1991},
  publisher={American Psychological Association}
}

@incollection{brown2015people,
	Author = {Brown-Schmidt, Sarah and Yoon, Si On and Ryskin, Rachel Anna},
	Booktitle = {Psychology of Learning and Motivation},
	Chapter = {3},
	Date-Added = {2018-09-24 14:22:49 +0200},
	Date-Modified = {2018-09-24 14:22:49 +0200},
	Pages = {59--99},
	Publisher = {Elsevier},
	Title = {People as contexts in conversation},
	Volume = {62},
	Year = {2015}
	}
