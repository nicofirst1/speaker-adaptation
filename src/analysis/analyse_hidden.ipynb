{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analyse_hidden.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dVBvonq7aVa_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/output_val')\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Qn-oBQPUau7W",
        "outputId": "1fe3e430-9a5e-4d92-b928-78b457aca31f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0464240aaaa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/output_val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/output_val'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diagnostic classification"
      ],
      "metadata": {
        "id": "ondL8JKbzNNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLF_TYPE = 'MLP'\n",
        "\n",
        "def train_and_classify(X, Y, classifier_type='MLP'):\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, test_size=0.2, random_state=1)\n",
        "  print(f'X_train: {X_train.shape}  X_test: {X_test.shape}  Y_train: {Y_train.shape}  Y_test: {Y_test.shape}')\n",
        "\n",
        "  if classifier_type == 'MLP':\n",
        "    clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, Y_train)\n",
        "  elif classifier_type == 'LR':\n",
        "    clf = LogisticRegression(random_state=1).fit(X_train, Y_train)\n",
        "  else:\n",
        "    raise ValueError()\n",
        "\n",
        "\n",
        "  Y_pred = clf.predict(X_test)\n",
        "  \n",
        "  return classification_report(Y_test, Y_pred)"
      ],
      "metadata": {
        "id": "ac3QCR4Oh17F"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict target domain from non-adapted hidden representation"
      ],
      "metadata": {
        "id": "4RlNVcXRzW25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "  X.append(eval(row['original h0']))\n",
        "  Y.append(row['target domain'])\n",
        "\n",
        "X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "print(train_and_classify(X, Y, CLF_TYPE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PebKWe-sbXeA",
        "outputId": "abb4295a-e819-4f04-bbf6-012eb411b4bb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (13, 512)  X_test: (4, 512)  Y_train: (13,)  Y_test: (4,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        food       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict target domain from adapted hidden representation"
      ],
      "metadata": {
        "id": "KPWMYlSTzkMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in np.arange(3):\n",
        "\n",
        "  print(f'Step {step}')\n",
        "  \n",
        "  X, Y = [], []\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "    X.append(eval(row[f'adapted h0 s{step}']))\n",
        "    Y.append(row['target domain'])\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "  print(train_and_classify(X, Y, CLF_TYPE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ4Uo0EYhErd",
        "outputId": "9e6cf78c-bef3-4844-fdc3-1e9f4c0369e2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0\n",
            "X_train: (13, 512)  X_test: (4, 512)  Y_train: (13,)  Y_test: (4,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        food       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "Step 1\n",
            "X_train: (13, 512)  X_test: (4, 512)  Y_train: (13,)  Y_test: (4,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        food       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "Step 2\n",
            "X_train: (13, 512)  X_test: (4, 512)  Y_train: (13,)  Y_test: (4,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        food       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict listener domain from adapted hidden representation"
      ],
      "metadata": {
        "id": "bX14vz7izpYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in np.arange(3):\n",
        "\n",
        "  print(f'Step {step}')\n",
        "\n",
        "  X, Y = [], []\n",
        "  for _, row in df.iterrows():\n",
        "    X.append(eval(row[f'adapted h0 s{step}']))\n",
        "    Y.append(row['listener domain'])\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "  print(train_and_classify(X, Y, CLF_TYPE))"
      ],
      "metadata": {
        "id": "Eg9m_qoHz6XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict listener domain from difference between adapted and non-adapted hidden representation"
      ],
      "metadata": {
        "id": "tA-RB_iU0BHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in np.arange(3):\n",
        "\n",
        "  print(f'Step {step}')\n",
        "\n",
        "  X, Y = [], []\n",
        "  for _, row in df.iterrows():\n",
        "    X.append(np.array(eval(row[f'adapted h0 s{step}'])) - np.array(eval(row['original h0'])))\n",
        "    Y.append(row['listener domain'])\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "  print(train_and_classify(X, Y, CLF_TYPE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkIvv80lb1KX",
        "outputId": "36cd5656-f502-41e9-df09-041baabe71a4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0\n",
            "X_train: (13, 512)  X_test: (4, 512)  Y_train: (13,)  Y_test: (4,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        food       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "Step 1\n",
            "X_train: (13, 512)  X_test: (4, 512)  Y_train: (13,)  Y_test: (4,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        food       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "Step 2\n",
            "X_train: (13, 512)  X_test: (4, 512)  Y_train: (13,)  Y_test: (4,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        food       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diagnostic clustering"
      ],
      "metadata": {
        "id": "ZezAMO-r0J28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_and_plot(X, Y, k=5):\n",
        "  kmeans = KMeans(n_clusters=k, random_state=1).fit(X)\n",
        "  Y_pred = kmeans.labels_\n",
        "\n",
        "  print(f'Adjusted rand score: {adjusted_rand_score(Y_pred, Y)}')\n",
        "\n",
        "  pca = PCA(2)\n",
        "  X_2dim = pca.fit_transform(X)\n",
        "  labels = np.unique(Y_pred)\n",
        "  \n",
        "  for i in labels:\n",
        "      plt.scatter(X_2dim[Y_pred == i , 0] , X_2dim[Y_pred == i , 1] , label = i)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  return kmeans, plt"
      ],
      "metadata": {
        "id": "0rFTHayx34s_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster non-adapted hidden representations (vs. target domains)"
      ],
      "metadata": {
        "id": "JOLYqBPo1mbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "  X.append(eval(row['original h0']))\n",
        "  Y.append(row['target domain'])\n",
        "\n",
        "X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "cluster_and_plot(X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "GwZhb3vWcLWp",
        "outputId": "11ee1823-0ca7-4b8f-baf5-866def20dd2e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a16250f59624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original h0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target domain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster adapted hidden representations (vs. target domains)\n",
        "\n"
      ],
      "metadata": {
        "id": "2QIuBljZ16jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in np.arange(3):\n",
        "\n",
        "  print(f'Step {step}')\n",
        "\n",
        "  X, Y = [], []\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "    X.append(eval(row[f'adapted h0 s{step}']))\n",
        "    Y.append(row['target domain'])\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "  cluster_and_plot(X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA-7I28UcPY-",
        "outputId": "260ee99d-8227-41c9-c219-5caf1f7009db"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster adapted hidden representations (vs. listener domains)\n"
      ],
      "metadata": {
        "id": "xYksOQR62EvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in np.arange(3):\n",
        "\n",
        "  print(f'Step {step}')\n",
        "\n",
        "  X, Y = [], []\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "    X.append(eval(row[f'adapted h0 s{step}']))\n",
        "    Y.append(row['listener domain'])\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "  cluster_and_plot(X, Y)"
      ],
      "metadata": {
        "id": "ui1RLIFymVQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster difference between adapted and non-adapted hidden representations (vs. listener domains)\n"
      ],
      "metadata": {
        "id": "OGFkt9P72MIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in np.arange(3):\n",
        "\n",
        "  print(f'Step {step}')\n",
        "\n",
        "  X, Y = [], []\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "    X.append(np.array(eval(row[f'adapted h0 s{step}'])) - np.array(eval(row['original h0'])))\n",
        "    Y.append(row['listener domain'])\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "  cluster_and_plot(X, Y)"
      ],
      "metadata": {
        "id": "E3JDpB1C2dgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}